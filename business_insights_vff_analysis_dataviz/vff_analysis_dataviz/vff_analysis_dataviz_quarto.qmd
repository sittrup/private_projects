---
title: "VFF"
subtitle: "Første semester projekt"
author: 
-   André Sittrup Olesen
-   Anja Leth Jensen
-   Camilla Agnes Sparre Andersen
-   Patrick Schumann
date: today
format: 
  pdf:
    toc: true
    toc-location: left
    code-fold: true
    code-summary: "Show the code"
editor: 
  markdown: 
    wrap: 72
fontsize: 12pt
mainfont: Arial
linestretch: 1.5
editor_options: 
  chunk_output_type: console
---

```{r, include=FALSE, echo=FALSE, cache=TRUE}

# Installer pacman
if (!requireNamespace("pacman", quietly = TRUE)) install.packages("pacman")

# Load pacman og installer pakker
pacman::p_load(tidyverse, readxl, lubridate, httr, jsonlite, 
               rvest, caret, car, randomForest, glmnet, 
               fastDummies, cowplot, car)

# Loader libraries
library(tidyverse) 
library(readxl)
library(lubridate)
library(httr)
library(jsonlite)
library(rvest)
library(caret)
library(car)         
library(randomForest)
library(glmnet)
library(fastDummies)
library(cowplot)    
library(car)

# ------------------------------------------------------------------------------
# INDLÆSNING AF GULD-DATA
# ------------------------------------------------------------------------------

guld_data <- readxl::read_excel("Guld.xlsx")

# Her konverteres dato, så det står i korrekt datoformat
# dplyr::mutate bruges til at oprette en ny kolonne 'Dato' med korrekt datoformat
# dplyr::case_when bruges til at konvertere tal, f.eks. 
# Hvis Dato kan konverteres til et tal, omdannes det til en dato med startpunkt "1899-12-30"
# Hvis Dato matcher mønsteret "dd.mm.yyyy", omdannes det til en dato ved hjælp af lubridate::dmy
# Hvis ingen af de to ovenstående betingelser er opfyldt, omdannes det til NA
guld_data <- guld_data |>
  dplyr::mutate(
    Dato = dplyr::case_when(
      suppressWarnings(!is.na(as.numeric(Dato))) ~ as.Date(as.numeric(Dato), origin="1899-12-30"),
      grepl("^\\d{2}\\.\\d{2}\\.\\d{4}$", Dato)   ~ lubridate::dmy(Dato),
      TRUE ~ as.Date(NA)
    )
  )

# Fjerner Gule_poletter_stk, laver Kamp om til en factor, fjerner NA
cleaned_data <- guld_data |>
  dplyr::select(-Gule_poletter_stk) |>
  dplyr::mutate(Kamp = as.factor(Kamp)) |>
  tidyr::drop_na()

# Beregner udnyttelsesgraden for hver række og tilføjer den som en ny kolonne i cleaned_data2
cleaned_data2 <- cleaned_data |>
  dplyr::mutate(udnyttelsesgraden = Guld_menu_stk / Antal_bestilte)

# ------------------------------------------------------------------------------
# HENT/GEM API-DATA (DMI)
# ------------------------------------------------------------------------------

# Her hentes data fra DMI's API og gemmes i en lokal RDS-fil, så vi ikke behøver at hente dataen hver gang
r_data_file <- "APIdata.rds"
APIdata     <- NULL

if (file.exists(r_data_file)) {
  message("Indlæser DMI-data fra lokal RDS-fil: ", r_data_file)
  APIdata <- readRDS(r_data_file)
} else {
  message("Ingen lokal APIdata fundet. Henter data fra DMI API...")
  
  base_url   <- "https://dmigw.govcloud.dk/v2/"
  info_url   <- "metObs/collections/observation/items?"
  api_key    <- "f21f4434-06af-4b0d-a00f-209da7929822"
  station_id <- "06060"
  
  unique_dates <- sort(unique(as.Date(cleaned_data2$Dato)))
  date_chunks  <- split(unique_dates, lubridate::floor_date(unique_dates, "month"))
  
  fetch_data_chunk <- function(dates) {
    chunk_responses <- list()
    for (this_date in dates) {
      start_datetime <- format(as.Date(this_date),    "%Y-%m-%dT00:00:00Z")
      end_datetime   <- format(as.Date(this_date)+1, "%Y-%m-%dT00:00:00Z")
      
      req_url  <- paste0("stationId=", station_id, "&datetime=", start_datetime, "/", end_datetime, "&limit=100000")
      full_url <- paste0(base_url, info_url, req_url, "&api-key=", api_key)
      
      api_call <- httr::GET(full_url)
      if (api_call$status_code != 200) {
        warning("API-kald mislykkedes [", api_call$status_code, "] for dato ", this_date)
        Sys.sleep(1)
        next
      }
      
      api_char <- rawToChar(api_call$content)
      api_JSON <- jsonlite::fromJSON(api_char, flatten=TRUE)
      if (is.null(api_JSON$features) || length(api_JSON$features) == 0) {
        warning("Ingen data for dato ", this_date)
        Sys.sleep(1)
        next
      }
      
      needed_cols <- c("properties.observed", "properties.parameterId", "properties.value")
      if (!all(needed_cols %in% colnames(api_JSON$features))) {
        warning("Forventede kolonner findes ikke for dato ", this_date)
        Sys.sleep(1)
        next
      }
      
      observations <- api_JSON$features |>
        dplyr::select(
          observed    = properties.observed,
          parameterId = properties.parameterId,
          Value       = properties.value
        ) |>
        # Tving Value til character fra start
        dplyr::mutate(Value = as.character(Value)) |>
        dplyr::mutate(
          Value = dplyr::if_else(
            grepl("^-?\\d+(\\.\\d+)?$", Value),
            Value,
            NA_character_   # NA af typen character
          ),
          Value = as.numeric(Value)
        )
      
      dmi <- observations |>
        dplyr::mutate(Dato = as.Date(substr(observed, 1, 10))) |>
        dplyr::group_by(Dato, parameterId) |>
        dplyr::summarise(Value = mean(Value, na.rm=TRUE), .groups="drop") |>
        tidyr::pivot_wider(names_from=parameterId, values_from=Value)
      
      chunk_responses <- append(chunk_responses, list(dmi))
      Sys.sleep(1)
    }
    if (length(chunk_responses) > 0) {
      dplyr::bind_rows(chunk_responses)
    } else {
      NULL
    }
  }
  
  api_responses <- list()
  for (chunk in date_chunks) {
    chunk_data <- fetch_data_chunk(chunk)
    if (!is.null(chunk_data)) {
      api_responses <- append(api_responses, list(chunk_data))
    }
  }
  
  if (length(api_responses) > 0) {
    APIdata <- dplyr::bind_rows(api_responses) |>
      dplyr::mutate(Dato = as.Date(Dato))
    message("API-data hentet fra DMI – gemmer i fil: ", r_data_file)
    saveRDS(APIdata, r_data_file)
  } else {
    warning("Ingen API-data hentet. Bruger cleaned_data2 som fallback.")
  }
}

if (!is.null(APIdata)) {
  final_data <- dplyr::left_join(cleaned_data2, APIdata, by="Dato")
} else {
  final_data <- cleaned_data2
}

# ------------------------------------------------------------------------------
# WEBSCRAPING (superstats.dk) + JOIN
# ------------------------------------------------------------------------------

# Opretter en mappe til dataen
data_dir <- "data"
if (!dir.exists(data_dir)) dir.create(data_dir)

# Opretter en vektor med sæsoner og en tom liste til at gemme dataen i
seasons <- paste0(2013:2024, "/", 2014:2025)
match_list <- list()

# Vi gør her det samme som med API, vi scraper for data på superstats og gemmer dem i en lokal CSV-fil
for (season_year in seasons) {
  file_season <- gsub("/", "-", season_year)
  local_file  <- file.path(data_dir, paste0(file_season, ".csv"))
  
  if (file.exists(local_file)) {
    message("Læser lokal CSV: ", local_file)
    table_data <- readr::read_csv(local_file, show_col_types=FALSE)
    match_list[[season_year]] <- table_data
  } else {
    match_url <- paste0("https://superstats.dk/program?season=", season_year)
    message("Scraper data for: ", season_year, " => ", match_url)
    
    table_data <- NULL
    try({
      html <- rvest::read_html(match_url)
      table_data_html <- html |>
        rvest::html_nodes("div#content") |>
        rvest::html_table()
      
      if (length(table_data_html) > 0 && nrow(table_data_html[[1]]) > 0) {
        if (is.null(colnames(table_data_html[[1]])) || any(colnames(table_data_html[[1]]) == "")) {
          colnames(table_data_html[[1]]) <- c("day", "date_time", "opponent", "goals", "audience", "referee", "channels")
        }
        
        table_data_processed <- table_data_html[[1]] |>
          dplyr::mutate(
            runde = dplyr::if_else(grepl("^Runde", day), gsub("Runde ", "", day), as.character(NA))
          ) |>
          tidyr::fill(runde, .direction="down") |>
          dplyr::filter(!grepl("^Runde", day)) |>
          dplyr::mutate(season=season_year)
        
        table_data <- table_data_processed
        readr::write_csv(table_data, local_file)
        message("Gemte scraping-resultat i: ", local_file)
        match_list[[season_year]] <- table_data
      } else {
        message("Ingen data fundet for sæson: ", season_year)
      }
    }, silent=FALSE)
    
    if (!is.null(table_data)) {
      match_list[[season_year]] <- table_data
    }
  }
}

# Formatering af dataen - vi splitter dataen i date og time og ændrer f.eks. "Ã¦" til "æ"
combined_match <- dplyr::bind_rows(match_list, .id="season")

combined_match <- combined_match |>
  dplyr::mutate(runde = dplyr::if_else(is.na(runde), 1L, as.integer(runde))) |>
  tidyr::separate(date_time, into=c("date", "time"), sep=" ") |>
  dplyr::mutate(across(where(is.character), ~ iconv(., from="UTF-8", to="latin1"))) |>
  dplyr::mutate(across(where(is.character), ~ stringr::str_replace_all(.,
                                                                       c("Ã¦"="æ", "Ã¸"="ø", "Ã…"="Å", "LÃ¸r"="Lør", "SÃ¸n"="Søn"))))

vff_matches <- combined_match |>
  dplyr::filter(grepl("VFF", opponent) | grepl("VFF", day)) |>
  dplyr::select(-day, -channels)

season_dates <- tibble::tibble(
  season = c("2013/2014", "2014/2015", "2015/2016", "2016/2017", "2017/2018",
             "2018/2019", "2019/2020", "2020/2021", "2021/2022", "2022/2023",
             "2023/2024", "2024/2025"),
  start_date = as.Date(c("2013-07-19", "2014-07-18", "2015-07-17", "2016-07-15",
                         "2017-07-14", "2018-07-13", "2019-07-12", "2020-09-11",
                         "2021-07-16", "2022-07-15", "2023-07-21", "2024-07-20")),
  end_date   = as.Date(c("2014-05-18", "2015-06-07", "2016-05-29", "2017-06-04",
                         "2018-05-27", "2019-05-26", "2020-07-26", "2021-05-28",
                         "2022-05-22", "2023-06-04", "2024-05-26", "2025-05-25"))
)

# Adskil kolonnerne 'day' og 'month', tilføj 'year' og 'dato' i korrekt format
# Konverter 'dato' til Date-format i både vff_matches og final_data
# Left join final_data og vff_matches på 'dato'
vff_matches <- vff_matches |>
  dplyr::mutate(
    day   = as.integer(stringr::str_extract(date, "^[0-9]+")),
    month = as.integer(stringr::str_extract(date, "(?<=/)[0-9]+"))
  ) |>
  dplyr::left_join(season_dates, by="season") |>
  dplyr::mutate(
    year = dplyr::if_else(
      (month > lubridate::month(start_date)) |
        (month == lubridate::month(start_date) & day >= lubridate::day(start_date)),
      lubridate::year(start_date),
      lubridate::year(end_date)
    ),
    dato = as.Date(paste(year, month, day, sep="-"), format="%Y-%m-%d")
  ) |>
  dplyr::select(date, time, opponent, goals, audience, referee, runde, season, dato)

final_data <- final_data |>
  dplyr::rename(dato = Dato) |>
  dplyr::mutate(dato = as.Date(dato))

vff_matches <- vff_matches |>
  dplyr::mutate(dato = as.Date(dato))

final_data_joined <- dplyr::left_join(final_data, vff_matches, by="dato")

# ------------------------------------------------------------------------------
# MODELTRÆNING, EVALUERING, PLOTS
# ------------------------------------------------------------------------------
data <- final_data_joined

# Konverter tekst->tal
convert_to_numeric <- function(x) {
  if (all(grepl("^-?\\d+(\\.\\d+)?$", x))) as.numeric(x) else x
}
data <- data |>
  dplyr::mutate(across(where(is.character), convert_to_numeric))

# => Inddrag dato, time, goals som faktor
if ("dato" %in% names(data)) data <- data |> dplyr::mutate(dato = as.factor(dato))
if ("time" %in% names(data)) data <- data |> dplyr::mutate(time = as.factor(time))
if ("goals" %in% names(data)) data <- data |> dplyr::mutate(goals = as.factor(goals))

# udnyttelsesgraden -> numeric
data <- data |> dplyr::mutate(udnyttelsesgraden = as.numeric(udnyttelsesgraden))

# Imputer numeric + sætter NA til median
numeric_cols <- names(data)[sapply(data, is.numeric)]
data <- data |> dplyr::mutate(across(all_of(numeric_cols), ~ tidyr::replace_na(., median(., na.rm=TRUE))))

# Evt. fjern
if ("date" %in% names(data)) data <- data |> dplyr::select(-date)
if ("opponent" %in% names(data)) data <- data |> dplyr::select(-opponent)

# Kamp, referee, season => factor
if ("Kamp" %in% names(data))    data <- data |> dplyr::mutate(Kamp = as.factor(Kamp))
if ("referee" %in% names(data)) data <- data |> dplyr::mutate(referee = as.factor(referee))
if ("season" %in% names(data))  data <- data |> dplyr::mutate(season = as.factor(season))

set.seed(42)
train_indices <- sample(nrow(data), size=floor(0.8 * nrow(data)))
train_data    <- data[train_indices, ]
test_data     <- data[-train_indices, ]

required_columns <- c("cloud_cover", "humidity", "wind_speed", "temp_dry", "precip_past1h", "pressure")

# Lav en dummy - her laves der en kolonne for hver kategori, værdien er 1 hvis der er data og 0 hvis der ikke er
categorical_vars <- c("Kamp", "referee", "season", "dato", "time", "goals")
categorical_vars <- intersect(categorical_vars, names(train_data))

train_data_encoded <- fastDummies::dummy_cols(
  train_data,
  select_columns         = categorical_vars,
  remove_selected_columns=TRUE,
  remove_first_dummy     =TRUE
)
test_data_encoded <- fastDummies::dummy_cols(
  test_data,
  select_columns         = categorical_vars,
  remove_selected_columns=TRUE,
  remove_first_dummy     =TRUE
)

# Her sikrer vi at train_data_encoded og test_data_encoded har de samme kolonner
all_cols <- union(names(train_data_encoded), names(test_data_encoded))
missing_cols_train <- setdiff(all_cols, names(train_data_encoded))
missing_cols_test  <- setdiff(all_cols, names(test_data_encoded))
train_data_encoded[missing_cols_train] <- 0
test_data_encoded[missing_cols_test]   <- 0

train_data_encoded <- train_data_encoded[, all_cols]
test_data_encoded  <- test_data_encoded[, all_cols]

# nearZeroVar(caret)
# Identificerer og fjerner kolonner med meget lav variation, da de ikke bidrager med nyttig information i modeller
nzv_cols <- caret::nearZeroVar(train_data_encoded)
nzv_cols <- setdiff(nzv_cols, which(names(train_data_encoded) %in% required_columns))
if (length(nzv_cols) > 0) {
  train_data_encoded <- train_data_encoded[, -nzv_cols, drop=FALSE]
  test_data_encoded  <- test_data_encoded[,  -nzv_cols, drop=FALSE]
}

# Corr check
# Refererer til at kontrollere korrelationen mellem variabler i et datasæt for at se, 
# om der er stærk sammenhæng mellem dem. Høj korrelation kan indikere redundans, hvilket kan føre til problemer i modeller
numeric_vars_train <- names(train_data_encoded)[sapply(train_data_encoded, is.numeric)]
train_data_encoded_cor <- train_data_encoded[, numeric_vars_train, drop=FALSE]

corr_matrix <- cor(train_data_encoded_cor, use="complete.obs")
high_corr   <- caret::findCorrelation(corr_matrix, cutoff=0.9)
req_idx     <- which(numeric_vars_train %in% required_columns)
high_corr   <- setdiff(high_corr, req_idx)
remove_these <- numeric_vars_train[high_corr]
if (length(remove_these) > 0) {
  train_data_encoded <- dplyr::select(train_data_encoded, -all_of(remove_these))
  test_data_encoded  <- dplyr::select(test_data_encoded,  -all_of(remove_these))
}

# train_data_encoded og test_data_encoded har nu de samme kolonner
if (all(required_columns %in% names(train_data_encoded))) {
  train_data_encoded <- train_data_encoded |>
    dplyr::mutate(
      cloud_humidity_interaction  = cloud_cover * humidity,
      wind_temp_interaction       = wind_speed * temp_dry,
      precip_pressure_interaction = precip_past1h * pressure
    )
  test_data_encoded <- test_data_encoded |>
    dplyr::mutate(
      cloud_humidity_interaction  = cloud_cover * humidity,
      wind_temp_interaction       = wind_speed * temp_dry,
      precip_pressure_interaction = precip_past1h * pressure
    )
}

# Imputer numeriske værdier - her erstatter vi NA med median, altså den midterste værdi
train_data_encoded <- train_data_encoded |>
  dplyr::mutate(across(where(is.numeric), ~ tidyr::replace_na(., median(., na.rm=TRUE))))
test_data_encoded  <- test_data_encoded |>
  dplyr::mutate(across(where(is.numeric), ~ tidyr::replace_na(., median(., na.rm=TRUE))))

# Check numeriske værdier 
# Kontroller at værdierne i datasættet, der ikke er numeriske, såsom tekst eller kategorier
not_numeric_train <- sapply(train_data_encoded, Negate(is.numeric))
if (any(not_numeric_train)) {
  cat("Ikke-numeriske kolonner i train_data_encoded:\n")
  print(names(train_data_encoded)[not_numeric_train])
}
not_numeric_test <- sapply(test_data_encoded, Negate(is.numeric))
if (any(not_numeric_test)) {
  cat("Ikke-numeriske kolonner i test_data_encoded:\n")
  print(names(test_data_encoded)[not_numeric_test])
}

train_data_encoded <- train_data_encoded |> dplyr::select(where(is.numeric))
test_data_encoded  <- test_data_encoded  |> dplyr::select(where(is.numeric))

stopifnot(all(sapply(train_data_encoded, is.numeric)))
stopifnot(all(sapply(test_data_encoded, is.numeric)))

# Opdeling af test og træningsdata
numeric_features <- setdiff(names(train_data_encoded), "udnyttelsesgraden")
preProcValues    <- caret::preProcess(train_data_encoded[, numeric_features], method=c("center", "scale"))
train_data_encoded[, numeric_features] <- predict(preProcValues, train_data_encoded[, numeric_features])
test_data_encoded[,  numeric_features] <- predict(preProcValues, test_data_encoded[,  numeric_features])

x_train <- as.matrix(dplyr::select(train_data_encoded, -udnyttelsesgraden))
y_train <- train_data_encoded[["udnyttelsesgraden"]]
x_test  <- as.matrix(dplyr::select(test_data_encoded,  -udnyttelsesgraden))
y_test  <- test_data_encoded[["udnyttelsesgraden"]]

# ------------------------------------------------------------------------------
# MODELLER - LM, lasso, ridge og random forrest
# ------------------------------------------------------------------------------

# Laver en liste til at gemme resultaterne i og sætter K fold til 5
results <- list()
train_control_cv <- caret::trainControl(method="cv", number=5, savePredictions="final", verboseIter=TRUE)

# LM(lineær model) på MSE, RMSE og R2
lm_cv_model <- caret::train(
  udnyttelsesgraden ~ .,
  data      = train_data_encoded,
  method    = "lm",
  trControl = train_control_cv
)
y_pred_lm  <- predict(lm_cv_model, newdata=test_data_encoded)
lm_mse      <- mean((y_test - y_pred_lm)^2)
lm_rmse     <- sqrt(lm_mse)
lm_r2       <- cor(y_test, y_pred_lm)^2
results[["Linear Regression (CV)"]] <- c("MSE"=lm_mse, "RMSE"=lm_rmse, "R2"=lm_r2)
lm_cv_results <- lm_cv_model$resample

# Lasso
lasso_model <- glmnet::cv.glmnet(x_train, y_train, alpha=1)
y_pred_lasso <- as.vector(predict(lasso_model, x_test, s=lasso_model$lambda.min))
lasso_mse  <- mean((y_test - y_pred_lasso)^2)
lasso_rmse <- sqrt(lasso_mse)
lasso_r2   <- cor(y_test, y_pred_lasso)^2
results[["Lasso Regression"]] <- c("MSE"=lasso_mse, "RMSE"=lasso_rmse, "R2"=lasso_r2)

# Ridge
ridge_model <- glmnet::cv.glmnet(x_train, y_train, alpha=0)
y_pred_ridge <- as.vector(predict(ridge_model, x_test, s=ridge_model$lambda.min))
ridge_mse  <- mean((y_test - y_pred_ridge)^2)
ridge_rmse <- sqrt(ridge_mse)
ridge_r2   <- cor(y_test, y_pred_ridge)^2
results[["Ridge Regression"]] <- c("MSE"=ridge_mse, "RMSE"=ridge_rmse, "R2"=ridge_r2)

# Random Forest
rf_cv_model <- caret::train(
  udnyttelsesgraden ~ .,
  data       = train_data_encoded,
  method     = "rf",
  trControl  = train_control_cv,
  ntree      = 100,
  importance = TRUE
)
y_pred_rf <- predict(rf_cv_model, newdata=test_data_encoded)
rf_mse  <- mean((y_test - y_pred_rf)^2)
rf_rmse <- sqrt(rf_mse)
rf_r2   <- cor(y_test, y_pred_rf)^2
results[["Random Forest (CV)"]] <- c("MSE"=rf_mse, "RMSE"=rf_rmse, "R2"=rf_r2)
rf_cv_results <- rf_cv_model$resample

# ------------------------------------------------------------------------------
# VISUALISERING
# ------------------------------------------------------------------------------
cv_results <- dplyr::bind_rows(
  lm_cv_results   |> dplyr::mutate(Model="Linear Regression (CV)"),
  rf_cv_results   |> dplyr::mutate(Model="Random Forest (CV)")
)

# Plot 1: Cross-validated RMSE
if (.Platform$OS.type=="windows") windows(title="RMSE Plot") else x11()
rmse_plot <- ggplot(cv_results, aes(x=Model, y=RMSE, fill=Model)) +
  geom_boxplot() + theme_minimal() +
  labs(title="Cross-Validated RMSE Comparison") +
  theme(legend.position="none")
print(rmse_plot)
ggsave("cv_rmse_comparison.png", plot=rmse_plot, width=8, height=6, dpi=300)

# Plot 2: Cross-validated R²
if (.Platform$OS.type=="windows") windows(title="R2 Plot") else x11()
r2_plot <- ggplot(cv_results, aes(x=Model, y=Rsquared, fill=Model)) +
  geom_boxplot() + theme_minimal() +
  labs(title="Cross-Validated R² Comparison") +
  theme(legend.position="none")
print(r2_plot)
ggsave("cv_r2_comparison.png", plot=r2_plot, width=8, height=6, dpi=300)

# Summaries
results_df <- as.data.frame(do.call(rbind, results), stringsAsFactors=FALSE) |>
  tibble::rownames_to_column(var="Model") |>
  dplyr::mutate(across(-Model, as.numeric))

best_model <- results_df %>% dplyr::arrange(MSE) %>% dplyr::slice(1)
message("Bedste model baseret på laveste MSE er: ", best_model$Model)

# Søjlediagrammer for MSE, RMSE, R2
metrics <- c("MSE", "RMSE", "R2")
for (met in metrics) {
  if (.Platform$OS.type=="windows") windows(title=paste(met, "Comparison")) else x11()
  p <- ggplot(results_df, aes(x=Model, y=.data[[met]], fill=Model)) +
    geom_bar(stat="identity", width=0.6) +
    labs(title=paste(met, "Comparison"), x="Model", y=met) +
    theme_minimal() +
    theme(legend.position="none")
  print(p)
  ggsave(paste0(met, "_comparison.png"), plot=p, width=8, height=6, dpi=300)
}

# Observeret vs forudsiget
obs_vs_pred <- function(y_obs, y_pred, model_name) {
  ggplot(data.frame(Observed=y_obs, Predicted=y_pred), aes(x=Observed, y=Predicted)) +
    geom_point(color="blue", alpha=0.6) +
    geom_abline(slope=1, intercept=0, color="red", linetype="dashed") +
    labs(title=model_name, x="Observeret", y="Forudsagt") +
    theme_minimal()
}

lm_plot    <- obs_vs_pred(y_test, y_pred_lm,    "Linear Regression (CV)")
lasso_plot <- obs_vs_pred(y_test, y_pred_lasso, "Lasso Regression")
ridge_plot <- obs_vs_pred(y_test, y_pred_ridge, "Ridge Regression")
rf_plot    <- obs_vs_pred(y_test, y_pred_rf,    "Random Forest (CV)")

if (.Platform$OS.type=="windows") windows(title="Obs vs Pred") else x11()
observed_vs_pred_combined <- cowplot::plot_grid(lm_plot, lasso_plot, ridge_plot, rf_plot,
                                                labels=c("A", "B", "C", "D"), ncol=2)
print(observed_vs_pred_combined)
ggsave("observed_vs_pred_combined.png", plot=observed_vs_pred_combined, width=12, height=10, dpi=300)

# Residual plots
residual_plot <- function(y_obs, y_pred, model_name) {
  residuals <- y_obs - y_pred
  plot_data <- data.frame(Fitted=y_pred, Residuals=residuals)
  ggplot(plot_data, aes(x=Fitted, y=Residuals)) +
    geom_point(color="darkgreen", alpha=0.6) +
    geom_hline(yintercept=0, color="red", linetype="dashed") +
    labs(title=model_name, x="Forudsagte værdier", y="Residualer") +
    theme_minimal()
}

lm_resid    <- residual_plot(y_test, y_pred_lm,    "Linear Regression")
lasso_resid <- residual_plot(y_test, y_pred_lasso, "Lasso Regression")
ridge_resid <- residual_plot(y_test, y_pred_ridge, "Ridge Regression")
rf_resid    <- residual_plot(y_test, y_pred_rf,    "Random Forest")

if (.Platform$OS.type=="windows") windows(title="Residual Plots") else x11()
residuals_combined <- cowplot::plot_grid(lm_resid, lasso_resid, ridge_resid, rf_resid,
                                         labels=c("A", "B", "C", "D"), ncol=2)
print(residuals_combined)
ggsave("residuals_combined.png", plot=residuals_combined, width=12, height=10, dpi=300)

# VIF & ALIAS
lm_full <- lm(udnyttelsesgraden ~ ., data=train_data_encoded)
aliases <- stats::alias(lm_full)
message("Alias (lineær afhængighed):")
print(aliases)
if ("vif" %in% ls("package:car")) {
  vif_values <- tryCatch(car::vif(lm_full), error=function(e) NULL)
  message("VIF values:")
  print(vif_values)
} else {
  message("car::vif ikke tilgængelig - springer over.")
}

###############################################################################
# FORFINING AF MODELLER
###############################################################################
# Formål:
# - Implementere ekstra Feature Engineering.
# - Udvide fjernelse af korrelerede predictorer.
# - Bruge Regularization (f.eks. Lasso/Elastic Net).
# - Tune hyperparametre for at reducere MSE og bevare fortolkelighed.
# - Til sidst sammenligne med de gamle modeller.

# Antag, at vi stadig har 'data', 'train_data_encoded', 'test_data_encoded', osv.
# fra den gamle kode. Vi vil lave en "version 2" og så sammenligne bagefter.

###############################################################################
# TRIN 1: Yderligere Feature Engineering
###############################################################################
# (a) Opret nye kolonner til 'dato' og 'time' for at fange "dag i ugen", "minutter siden midnat" mm.
#    - Dette hjælper modellen med at se mønstre i tid på dagen, sæson, etc.
#    - Vores gamle 'data' har "dato" og "time" som factor. Vi vil skabe nye numeric kolonner.
#    - Her viser vi en pseudo:
#    - day_of_year = lubridate::yday(as.Date(as.character(dato))),
#    - Eksempel: dag_i_ugen = lubridate::wday(mydates, week_start=1)
#    - For now we do a placeholder:
#    - ^^^ SKIFT TIL en reel beregning baseret på as.Date(dato)!

# Lav en kopi af data for nye features (vi kalder den data_v2)
data_v2 <- data

# (a1) Eksempel: dag_i_ugen (Monday=1, Tuesday=2, ...)
#     - Giver et numerisk eller factor-lignende signal om ugedag.
#     - Nyttigt hvis 'dato' reelt dækker flere uger/måneder.
data_v2 <- data_v2 |>
  dplyr::mutate(
    dag_i_ugen = sample(1:7, size=nrow(data_v2), replace=TRUE) 
  )

# (a2) Eksempel: konverter "time" factor til numeric "minutes since midnight"
#     - Hjælper hvis vi har timeslots som "13:00", "18:30" etc.
#     - Giver en single numeric der fanger tid på dagen.
data_v2 <- data_v2 |>
  dplyr::mutate(
    time_char = as.character(time),
    hour_part = as.numeric(substr(time_char, 1, 2)),
    min_part  = as.numeric(substr(time_char, 4, 5)),
    minutes_since_midnight = hour_part * 60 + min_part
  )

# (a3) For 'goals' = "2-1", splint op i home_goals, away_goals.
#     - Giver mere meningsfuld numeric kolonne end en factor "2-1".
data_v2 <- data_v2 |>
  dplyr::mutate(
    goals_char   = as.character(goals),
    home_goals   = as.numeric(stringr::str_extract(goals_char, "^[0-9]+")),
    away_goals   = as.numeric(stringr::str_extract(goals_char, "(?<=-)[0-9]+")),
    goal_diff    = home_goals - away_goals
  )

#  Bemærk: Ovenstående forudsætter at "2-1" altid er i format "X-Y" med enkel-cifre.
#  Hvis du har to cifre (f.eks. "12-10"), juster dine regex etc.

# (a4) Evt. fjern de gamle factor-variabler 'time', 'goals' hvis du vil. 
#      Men her lader vi dem leve for sammenligning.
#      For example:
# data_v2 <- data_v2 %>% select(-time, -goals)

# TIPS:
# - Ovenstående er demonstration. Du vil reelt parse "dato" til date og vurdere day_of_year, wday, etc.
# - Samme for time. Her er blot en skitse for at vise princippet.

###############################################################################
# TRIN 2: Fjern (endnu mere aggressivt) korrelerede / lav-varians prediktorer
###############################################################################
# Hvorfor?
# - Vi har kun ~98 rækker og 50+ features. Overfitting og rank deficiency er sandsynligt.
# - Kører vi en ny correlation-check efter de nye features, 
#   for at se om home_goals, away_goals, goal_diff, minutes_since_midnight etc.
#   er stærkt korreleret.
###############################################################################

# Kør en "v2" pipeline a la vores gamle code, men på data_v2.

# 1) dummy-encode (hvis relevant)
# 2) nearZeroVar
# 3) findCorrelation(0.8 fx) – 0.9 might be too lenient
# 4) remove
# 5) re-run Lasso, etc.

# Eksempel (sketch) i nye objekter data_v2_encoded, for at adskille fra "train_data_encoded"
data_v2_encoded <- data_v2

# Her kunne vi kopiere samme pipeline: 
# - train/test-split
# - dummy_cols
# - nearZeroVar
# - findCorrelation
# - remove strong correlation
# - scale
# - model building
# men for demonstrationens skyld laver vi det i en genvej:

###############################################################################
# TRIN 3: Vi laver en Lasso/Elastic Net med hyperparameter-tuning
###############################################################################
# Hvorfor?
# - Lasso fjerner uvæsentlige variable (tvinger dem til 0).
# - For 98 obs / 50+ features, regularization er afgørende.
###############################################################################

# (Eksempel) Vi genbruger x_train, y_train, men hvis vi vil 
#  medtage vores nye features, skal vi først definere x_train_v2, y_train_v2 etc.
#  
#   1) Split data_v2 i train_v2 og test_v2
#   2) dummy encode
#   3) scale
#   4) x_train_v2, y_train_v2, x_test_v2, y_test_v2
#   5) glmnet::cv.glmnet(..., alpha=1) for Lasso

# Her viser vi en pseudo-løsning:

set.seed(42) # For reproducibility
train_indices_v2 <- sample(nrow(data_v2), size = floor(0.8 * nrow(data_v2)))
train_v2  <- data_v2[train_indices_v2, ]
test_v2   <- data_v2[-train_indices_v2, ]

# For demonstration, lav en factor->dummy approach 
categorical_vars_v2 <- c("Kamp", "referee", "season", "dato")
categorical_vars_v2 <- intersect(categorical_vars_v2, names(train_v2))

train_v2_encoded <- fastDummies::dummy_cols(
  train_v2,
  select_columns = categorical_vars_v2,
  remove_selected_columns=TRUE,
  remove_first_dummy=TRUE
)
test_v2_encoded <- fastDummies::dummy_cols(
  test_v2,
  select_columns = categorical_vars_v2,
  remove_selected_columns=TRUE,
  remove_first_dummy=TRUE
)

# Sørg for samme kolonner
all_cols_v2 <- union(names(train_v2_encoded), names(test_v2_encoded))
missing_cols_train_v2 <- setdiff(all_cols_v2, names(train_v2_encoded))
missing_cols_test_v2  <- setdiff(all_cols_v2, names(test_v2_encoded))

train_v2_encoded[missing_cols_train_v2] <- 0
test_v2_encoded[missing_cols_test_v2]   <- 0
train_v2_encoded <- train_v2_encoded[, all_cols_v2]
test_v2_encoded  <- test_v2_encoded[, all_cols_v2]

# Fjern nul varians
nzv_cols_v2 <- caret::nearZeroVar(train_v2_encoded)
if (length(nzv_cols_v2) > 0) {
  train_v2_encoded <- train_v2_encoded[,-nzv_cols_v2,drop=FALSE]
  test_v2_encoded  <- test_v2_encoded[ ,-nzv_cols_v2,drop=FALSE]
}

# Fjern eventuelt korrelerede funktioner ved f.eks. 0,8
num_cols_v2 <- names(train_v2_encoded)[sapply(train_v2_encoded, is.numeric)]
corr_mat_v2 <- cor(train_v2_encoded[, num_cols_v2, drop=FALSE], use="complete.obs")
hi_corr_v2  <- caret::findCorrelation(corr_mat_v2, cutoff=0.8)
if (length(hi_corr_v2) > 0) {
  remove_these_v2 <- num_cols_v2[hi_corr_v2]
  train_v2_encoded <- train_v2_encoded %>% dplyr::select(-all_of(remove_these_v2))
  test_v2_encoded  <- test_v2_encoded  %>% dplyr::select(-all_of(remove_these_v2))
}

# Indsæt median ved nyopståede NAer
train_v2_encoded <- train_v2_encoded |>
  dplyr::mutate(across(where(is.numeric), ~ tidyr::replace_na(., median(., na.rm=TRUE))))
test_v2_encoded  <- test_v2_encoded |>
  dplyr::mutate(across(where(is.numeric), ~ tidyr::replace_na(., median(., na.rm=TRUE))))

# Scale
numeric_feats_v2 <- setdiff(names(train_v2_encoded), "udnyttelsesgraden")
pp_v2 <- caret::preProcess(train_v2_encoded[, numeric_feats_v2], method=c("center", "scale"))
train_v2_encoded[, numeric_feats_v2] <- predict(pp_v2, train_v2_encoded[, numeric_feats_v2])
test_v2_encoded[,  numeric_feats_v2] <- predict(pp_v2, test_v2_encoded[,  numeric_feats_v2])

# Definer x,y
x_train_v2 <- as.matrix(dplyr::select(train_v2_encoded, -udnyttelsesgraden))
y_train_v2 <- train_v2_encoded[["udnyttelsesgraden"]]
x_test_v2  <- as.matrix(dplyr::select(test_v2_encoded,  -udnyttelsesgraden))
y_test_v2  <- test_v2_encoded[["udnyttelsesgraden"]]

# Lasso + hyperparameter tuning => glmnet::cv.glmnet does cross-validation over lambda
lasso_model_v2 <- glmnet::cv.glmnet(x_train_v2, y_train_v2, alpha=1) 
y_pred_lasso_v2 <- as.vector(predict(lasso_model_v2, x_test_v2, s=lasso_model_v2$lambda.min))

lasso_mse_v2  <- mean((y_test_v2 - y_pred_lasso_v2)^2)
lasso_rmse_v2 <- sqrt(lasso_mse_v2)
lasso_r2_v2   <- cor(y_test_v2, y_pred_lasso_v2)^2

cat("\nNyt Lasso (Feature Eng + Corr Removal) - MSE:", lasso_mse_v2,
    "RMSE:", lasso_rmse_v2, "R2:", lasso_r2_v2, "\n")

###############################################################################
# TRIN 4: Visualisering + Sammenligning med gamle modeller
###############################################################################
# Hvorfor?
# - Vi vil gerne se om "Nye features + aggressiv corr removal + Lasso" forbedrer MSE 
#   ift. de gamle modeller (LM old, Lasso old, Ridge old, RF old).
###############################################################################

# Fx:
old_results <- results_df # Fra gamle pipeline
# Se ny Lasso:
# vi laver en ny row:
new_lasso_row <- data.frame(
  Model="New Lasso (featEng + corrRem)",
  MSE = lasso_mse_v2,
  RMSE= lasso_rmse_v2,
  R2  = lasso_r2_v2
)

new_results_df <- dplyr::bind_rows(old_results, new_lasso_row)

# Print
cat("\nGamle vs. Nye resultater:\n")
print(new_results_df)

# Vi kan også lave et bar-plot eller box-plot (ligner vores gamle plots, men med ny data frame)
# For demonstration:
if (.Platform$OS.type=="windows") windows(title="Model Comparison (Old vs. New)") else x11()
comp_plot <- ggplot(new_results_df, aes(x=Model, y=MSE, fill=Model)) +
  geom_bar(stat="identity", width=0.6) +
  labs(title="Comparing Old vs. New Models (MSE)", x="Model", y="MSE") +
  theme_minimal() + 
  theme(legend.position="none")

print(comp_plot)
ggsave("model_comparison_old_new.png", plot=comp_plot, width=8, height=6, dpi=300)

# Vi gentager for RMSE, R2 etc.

###############################################################################
# Andre mulige steps:
# - Tuning RandomForest (mtry, ntree)
# - Tuning alpha i glmnet => fx alpha=0.5 for Elastic Net
# - Tjek varImp i RF for "nye" feature-set.
###############################################################################

# Slut på vores nye segment
# - Hermed har vi en demonstration af, hvordan vi kan tilføje nye features,
#   fjerne korrelation, lave Lasso, og sammenligne med "old" resultaterne.

###############################################################################
# VISE HVILKE FEATURES FORBLIVER (NONZERO) I NY LASSO (FEATURE ENG + CORR REM)
###############################################################################
# Hvorfor gør vi det?
# - For at se præcis hvilke variabler Lasso har beholdt og hvilke der er sat til 0.
# - Hjælper med fortolkning og viden om, hvilke parametre der driver udnyttelsesgraden.

# 1) Hent coefficient-matrix fra glmnet-lasso
lasso_coefs_v2 <- coef(lasso_model_v2, s = lasso_model_v2$lambda.min)

# 2) Lav det om til en data.frame for nem visning
lasso_coefs_v2_df <- as.data.frame(as.matrix(lasso_coefs_v2))
colnames(lasso_coefs_v2_df) <- "Coefficient"
lasso_coefs_v2_df <- lasso_coefs_v2_df %>%
  tibble::rownames_to_column("Feature")

# 3) Filtrer væk de 0-koefficienter (Lasso sætter mange til 0)
nonzero_coefs_v2_df <- lasso_coefs_v2_df %>%
  dplyr::filter(Coefficient != 0)

# 4) Print
cat("\nIkke-nul Lasso-koefficienter (New Lasso):\n")
print(nonzero_coefs_v2_df)

# Vi kan evt. sortere efter absolut værdi for at se vigtigste først
nonzero_coefs_v2_df <- nonzero_coefs_v2_df %>%
  dplyr::arrange(dplyr::desc(abs(Coefficient)))

cat("\nSorteret efter størst absolut koefficient:\n")
print(nonzero_coefs_v2_df)

###############################################################################
# AFSNIT 6: IMPLEMENTERING MED FÅ (CUT-DOWN) VARIABLER
###############################################################################
# Formål:
#  1) Vi beholder kun en lille samling af variabler, som giver mening:
#     - Alle fra Guld-menu (Antal_bestilte, Guld_menu_stk, udnyttelsesgraden, etc.)
#     - Vejr => Good/Moderate/Bad (kategori) i stedet for 10+ vejrrapporter.
#     - Ugedag (weekday) + Time of day (evt. numeric)
#     - Rolling variable for 'goals' og 'audience'
#     - Dropper "referee," "channels," "season," "runde," etc.
#  2) Bygger nye pipelines i en "data_cut" version
#  3) Rerun LM, Lasso, Ridge, RF => Sammenligner med eksisterende resultater

###############################################################################
# TRIN 1: KONSTRUÉR "data_cut" MED FÆRRE VARIABLER
###############################################################################
# Hvorfor?
# - Vi vil gøre modellen mere fortolkelig og kun bruge variabler, 
#   der giver mening ift. at forudsige 'udnyttelsesgraden' før en kamp.

# (a) Lav en kopi af 'data'
data_cut <- data

# (b) Drop kolonner, hvis de findes, som vi ikke ønsker: referee, channels, season, runde, etc.
#     Bemærk, at de måske allerede er droppet i tidligere trin, 
#     men vi viser det her som eksempel:
drop_cols <- c("referee", "channels", "season", "runde")
drop_cols <- intersect(drop_cols, names(data_cut))
data_cut  <- data_cut %>% dplyr::select(-all_of(drop_cols))

# (c) Vi omdanner weather-variabler til en kategori: "Good," "Moderate," "Bad"
#     Eksempel: Vi baserer det på 'precip_past1h' og 'temp_dry' 
#     eller en kombination. Her viser vi en pseudo-løsning:
data_cut <- data_cut %>%
  dplyr::mutate(
    # Eksempel: "good" hvis temp_dry>15 og precip_past1h <0.5,
    # "moderate" hvis temp_dry>5 og <15, "bad" hvis temp_dry<5 eller precip>2, etc.
    weather_cat = dplyr::case_when(
      (temp_dry > 15 & precip_past1h < 0.5)       ~ "Good",
      (temp_dry > 5  & temp_dry <=15)            ~ "Moderate",
      TRUE                                       ~ "Bad"     
    )
  )

# (d) Ugedag: alligevel har vi  'dato' => 
#     Vi laver en "weekday" => Monday=1, Tuesday=2, etc. 
#     for demonstration, vi bruger lubridate::wday():
data_cut <- data_cut %>%
  dplyr::mutate(weekday = lubridate::wday(dato, week_start=1, label=FALSE)
                # => 1=Monday, 2=Tuesday, ...
  )

# (e) Time of day => numeric (feks 'minutes_since_midnight') 
if ("time" %in% names(data_cut)) {
  data_cut <- data_cut %>%
    dplyr::mutate(
      time_char = as.character(time),
      hour_part = as.numeric(substr(time_char, 1, 2)),
      min_part  = as.numeric(substr(time_char, 4, 5)),
      minutes_since_midnight = hour_part*60 + min_part
    )
}

# (f) Rolling variable for goals & audience
#     fx 'rolling_goals_3' => gennemsnit af de sidste 3 kampe
#     - Sortér data_cut efter dato (hvis row er unik pr kamp)
data_cut <- data_cut %>%
  dplyr::arrange(dato) %>%
  dplyr::mutate(
    # Hvis 'goals' er splitted => home_goals, away_goals => tot_goals=home+away
    # men her hvis 'goals' er factor, define numeric tot_goals
    # demonstration:
    tot_goals = ifelse(is.na(goals), 0, 2), # fx pseudo
    # rolling_3: 
    rolling_goals_3 = (dplyr::lag(tot_goals,1,default=0)
                       +dplyr::lag(tot_goals,2,default=0)
                       +dplyr::lag(tot_goals,3,default=0))/3,
    # Gør det samme for audience
    rolling_audience_3 = (dplyr::lag(audience,1,default=0)
                          +dplyr::lag(audience,2,default=0)
                          +dplyr::lag(audience,3,default=0))/3
  )

# (g) Opponent Team => "opponent_importance" = 1 if big rival / 0 else
#     for demonstration, we define everything 0 unless it's "FC Rival"
if ("opponent" %in% names(data_cut)) {
  data_cut <- data_cut %>%
    dplyr::mutate(
      opponent_importance = dplyr::if_else(
        stringr::str_detect(opponent,"Rival"), 
        1, 0
      )
    )
}

###############################################################################
# TRIN 2: LAV MODEL-PIPELINE MED CUT-DOWN VARIABLER
###############################################################################
# - Dummy-encode 'weather_cat'
# - nearZeroVar, findCorrelation
# - scale
# - Bygger 4 modeller (LM, Lasso, Ridge, RF)
# - Sammenligner

# 1) => Split train/test (80/20) 5 fold 
set.seed(42) 
cut_indices <- sample(nrow(data_cut), size=floor(0.8 * nrow(data_cut)))
train_cut <- data_cut[cut_indices, ]
test_cut  <- data_cut[-cut_indices, ]

# 2) Vælg kun relevante kolonner => 
#    c("udnyttelsesgraden","Antal_bestilte","Guld_menu_stk","weekday","minutes_since_midnight",
#    "weather_cat","opponent_importance","rolling_goals_3","rolling_audience_3")
desired_cols <- c(
  "udnyttelsesgraden","Antal_bestilte","Guld_menu_stk",
  "weekday","minutes_since_midnight",
  "weather_cat","opponent_importance",
  "rolling_goals_3","rolling_audience_3"
)
desired_cols <- intersect(desired_cols, names(train_cut))

train_cut <- train_cut[,desired_cols, drop=FALSE]
test_cut  <- test_cut[, desired_cols, drop=FALSE]

# 3) Dummy 'weather_cat'
vars_to_dummy <- c("weather_cat")
vars_to_dummy <- intersect(vars_to_dummy, names(train_cut))

train_cut_enc <- fastDummies::dummy_cols(
  train_cut,
  select_columns=vars_to_dummy,
  remove_selected_columns=TRUE,
  remove_first_dummy=TRUE
)
test_cut_enc <- fastDummies::dummy_cols(
  test_cut,
  select_columns=vars_to_dummy,
  remove_selected_columns=TRUE,
  remove_first_dummy=TRUE
)

# Sørg for samme kolonner
all_cut_cols <- union(names(train_cut_enc), names(test_cut_enc))
missing_train_cut <- setdiff(all_cut_cols, names(train_cut_enc))
missing_test_cut  <- setdiff(all_cut_cols, names(test_cut_enc))

train_cut_enc[missing_train_cut] <- 0
test_cut_enc[missing_test_cut]   <- 0
train_cut_enc <- train_cut_enc[, all_cut_cols]
test_cut_enc  <- test_cut_enc[, all_cut_cols]

# 4) nearZeroVar 
nzv_cut <- caret::nearZeroVar(train_cut_enc)
if (length(nzv_cut) > 0) {
  train_cut_enc <- train_cut_enc[,-nzv_cut,drop=FALSE]
  test_cut_enc  <- test_cut_enc[ ,-nzv_cut,drop=FALSE]
}

# 5) findCorrelation (0.8)
num_vars_cut <- names(train_cut_enc)[sapply(train_cut_enc,is.numeric)]
corr_cut <- cor(train_cut_enc[,num_vars_cut,drop=FALSE], use="complete.obs")
hi_corr_cut <- caret::findCorrelation(corr_cut, cutoff=0.8)
if (length(hi_corr_cut) > 0) {
  remove_vars <- num_vars_cut[hi_corr_cut]
  train_cut_enc <- train_cut_enc %>% dplyr::select(-all_of(remove_vars))
  test_cut_enc  <- test_cut_enc  %>% dplyr::select(-all_of(remove_vars))
}

# 6) Lav NAer om til median
train_cut_enc <- train_cut_enc |>
  dplyr::mutate(across(where(is.numeric), ~ tidyr::replace_na(., median(., na.rm=TRUE))))
test_cut_enc  <- test_cut_enc |>
  dplyr::mutate(across(where(is.numeric), ~ tidyr::replace_na(., median(., na.rm=TRUE))))

# 7) scale
final_feats_cut <- setdiff(names(train_cut_enc), "udnyttelsesgraden")
pp_cut <- caret::preProcess(train_cut_enc[, final_feats_cut], method=c("center", "scale"))
train_cut_enc[, final_feats_cut] <- predict(pp_cut, train_cut_enc[, final_feats_cut])
test_cut_enc[,  final_feats_cut] <- predict(pp_cut, test_cut_enc[,  final_feats_cut])

# 8) x,y til træning
x_train_cut <- as.matrix(dplyr::select(train_cut_enc, -udnyttelsesgraden))
y_train_cut <- train_cut_enc[["udnyttelsesgraden"]]
x_test_cut  <- as.matrix(dplyr::select(test_cut_enc, -udnyttelsesgraden))
y_test_cut  <- test_cut_enc[["udnyttelsesgraden"]]

###############################################################################
# TRIN 3: BYG 4 MODELLER (LM, Lasso, Ridge, RF) OG SAMMENLIGN
###############################################################################

cut_results <- list()
train_ctrl_cut <- caret::trainControl(method="cv", number=5, savePredictions="final")

### 1) LM 
lm_cut_model <- caret::train(
  udnyttelsesgraden ~ .,
  data      = train_cut_enc,
  method    = "lm",
  trControl = train_ctrl_cut
)
lm_cut_pred <- predict(lm_cut_model, newdata=test_cut_enc)
lm_cut_mse  <- mean((y_test_cut - lm_cut_pred)^2)
lm_cut_rmse <- sqrt(lm_cut_mse)
lm_cut_r2   <- cor(y_test_cut, lm_cut_pred)^2
cut_results[["CutDown LM"]] <- c(MSE=lm_cut_mse, RMSE=lm_cut_rmse, R2=lm_cut_r2)
lm_cut_cv   <- lm_cut_model$resample

### 2) Lasso
lasso_cut_model <- glmnet::cv.glmnet(x_train_cut, y_train_cut, alpha=1)
lasso_cut_pred  <- as.vector(predict(lasso_cut_model, x_test_cut, s=lasso_cut_model$lambda.min))
lasso_cut_mse   <- mean((y_test_cut - lasso_cut_pred)^2)
lasso_cut_rmse  <- sqrt(lasso_cut_mse)
lasso_cut_r2    <- cor(y_test_cut, lasso_cut_pred)^2
cut_results[["CutDown Lasso"]] <- c(MSE=lasso_cut_mse, RMSE=lasso_cut_rmse, R2=lasso_cut_r2)

### 3) Ridge
ridge_cut_model <- glmnet::cv.glmnet(x_train_cut, y_train_cut, alpha=0)
ridge_cut_pred  <- as.vector(predict(ridge_cut_model, x_test_cut, s=ridge_cut_model$lambda.min))
ridge_cut_mse   <- mean((y_test_cut - ridge_cut_pred)^2)
ridge_cut_rmse  <- sqrt(ridge_cut_mse)
ridge_cut_r2    <- cor(y_test_cut, ridge_cut_pred)^2
cut_results[["CutDown Ridge"]] <- c(MSE=ridge_cut_mse, RMSE=ridge_cut_rmse, R2=ridge_cut_r2)

### 4) Random Forest
rf_cut_model <- caret::train(
  udnyttelsesgraden ~ .,
  data      = train_cut_enc,
  method    = "rf",
  trControl = train_ctrl_cut,
  ntree     = 100,
  importance= TRUE
)
rf_cut_pred <- predict(rf_cut_model, newdata=test_cut_enc)
rf_cut_mse  <- mean((y_test_cut - rf_cut_pred)^2)
rf_cut_rmse <- sqrt(rf_cut_mse)
rf_cut_r2   <- cor(y_test_cut, rf_cut_pred)^2
cut_results[["CutDown RF"]] <- c(MSE=rf_cut_mse, RMSE=rf_cut_rmse, R2=rf_cut_r2)

###############################################################################
# TRIN 4: SAMMENLIGN MED EKSISTERENDE MODELLER
###############################################################################
# (a) Omdan cut_results til data.frame
cut_results_df <- as.data.frame(do.call(rbind, cut_results)) %>%
  tibble::rownames_to_column("Model")

# (b) Sammenlign med 'results_df'
#     Bemærk, at 'results_df' har kolonner: "Model", "MSE", "RMSE", "R2"
#     Vi binder dem sammen
if (exists("results_df")) {
  new_compare_df <- dplyr::bind_rows(results_df, cut_results_df)
  cat("\nSammenligning: Gamle vs. CutDown Models\n")
  print(new_compare_df)
  # Plot med old vs cutdown
  if (.Platform$OS.type=="windows") windows(title="Old vs. CutDown Models") else x11()
  comp2_plot <- ggplot(new_compare_df, aes(x=Model, y=MSE, fill=Model)) +
    geom_bar(stat="identity", width=0.6) +
    labs(title="Comparing Old vs. CutDown Models (MSE)", x="Model", y="MSE") +
    theme_minimal() +
    theme(legend.position="none")
  print(comp2_plot)
  ggsave("CutDown_vs_Old.png", plot=comp2_plot, width=8, height=6, dpi=300)
} else {
  cat("\nresults_df not found. We'll just show the new cut-down results.\n")
  print(cut_results_df)
}

###############################################################################
# AFSNIT 7: HVILKE VARIABLER ER VIGTIGE I CUT-DOWN RANDOM FOREST?
###############################################################################
# Hvorfor?
# - Vi vil se, hvilke features i vores "cut-down" sæt der forklarer mest 
#   af udnyttelsesgraden. De mest betydningsfulde variabler har 
#   størst betydning

# 1) Hent importance via caret::varImp
rf_cut_importance <- caret::varImp(rf_cut_model)$importance

# 2) Gør det til en data.frame
rf_cut_importance_df <- rf_cut_importance |>
  tibble::rownames_to_column("Feature") |>
  dplyr::arrange(dplyr::desc(Overall))

# 3) Print top 10, fx
cat("\nRandom Forest (Cut-Down) Variable Importance:\n")
print(rf_cut_importance_df %>% head(10))

# 4) Plot i en bar-chart
if (.Platform$OS.type=="windows") windows(title="Cut-Down RF Importance") else x11()
rf_cut_imp_plot <- rf_cut_importance_df |>
  dplyr::slice(1:10) |>
  ggplot(aes(x=reorder(Feature, Overall), y=Overall)) +
  geom_bar(stat="identity", fill="steelblue") +
  coord_flip() +
  labs(title="Top 10 Variable Importance - CutDown Random Forest",
       x="Feature", y="Importance") +
  theme_minimal()

print(rf_cut_imp_plot)
ggsave("CutDown_RF_VarImportance.png", plot=rf_cut_imp_plot, width=8, height=6, dpi=300)

###############################################################################
# LASSO: HENT NONZERO COEFFS I CUT-DOWN LASSO (uden “V1”-fejl)
###############################################################################
# 1) Få coefficient-matrix fra glmnet-lasso for min lambda
lasso_cut_coefs <- coef(lasso_cut_model, s=lasso_cut_model$lambda.min)

# 2) Omform til data.frame
#    Bemærk: as.matrix(...) ofte har 1 kolonne, men dens navn er ikke “V1.”
#    Det kan være “s0”, “s1,” etc.
lasso_cut_coefs_mat <- as.matrix(lasso_cut_coefs)

# Ændre navnet til "Coefficient"
colnames(lasso_cut_coefs_mat) <- "Coefficient"

# 3) Lav til data.frame + rownames til kolonne
lasso_cut_coefs_df <- as.data.frame(lasso_cut_coefs_mat) |>
  tibble::rownames_to_column("Feature")

# 4) Filter: behold dem, der != 0
nonzero_cut_coefs_df <- lasso_cut_coefs_df |>
  dplyr::filter(Coefficient != 0)

# Sorter i faldende rækkefølge efter absolut koefficient
nonzero_cut_coefs_df <- nonzero_cut_coefs_df |>
  dplyr::arrange(dplyr::desc(abs(Coefficient)))

cat("\nIkke-nul Lasso-koefficienter i CutDown Lasso:\n")
print(nonzero_cut_coefs_df)



```


# 1. Resumé

Formålet med dette projekt er at undersøge Viborg Fodsports Forening’s udfordringer med at forudsige fremmødet af VIP-gæster med guldmenu-billetter. Uoverensstemmelser mellem bestilte og benyttede billetter medfører ineffektiv ressourceanvendelse, madspild og forringede gæste/netværks-oplevelser, hvilket strider imod organisationens mission om at skabe unikke oplevelser og udnytte deres grønne potentiale.
Dataindsamlingen omfattede en Excel-fil med interne data fra VFF, eksternt indhentede vejrdata fra DMI og kampinformationer fra Superstats. Disse blev suppleret med semistrukturerede interviews med fire medarbejdere og tre praktikanter fra organisationen, som repræsenterede flere afdelinger. Interviewene gav indsigt i interne organisatoriske datarelaterede udfordringer såsom silo-dannelser og manglende dataintegration. 
CRISP-DM blev anvendt som ramme for analyseprocessen, og R-studio blev brugt til modellering og visualisering.
Projektet udviklede og testede flere prædiktionsmodeller, hvor Random Forest viste den højeste præcision. Analysen identificerede vejrforhold og kampkontekst som afgørende faktorer for fremmødet. Begrænset adgang til data har dog påvirket projektets konklusioner negativt ved at reducere modellernes anvendelighed og præcision. En udvidet dataindsamling, der inkluderer flere kunderelevante data såsom adfærd, præferencer og demografi, vil kunne styrke analyserne og prædiktionsmodellerne og samtidig forbedre VFF’s evne til at træffe mere informerede og datadrevne beslutninger.

Anbefalinger
Organisatorisk transformation: Implementering af Kotter’s 8-trins model anbefales for at fremme en fælles kultur for datahåndtering og reducere silo-dannelser. Dette vil skabe en stærkere organisatorisk base.
Centralisering af data: Etablering af et Datawarehouse skal understøtte ensartet dataopbevaring, deling og analyse på tværs af afdelinger.
Forbedring af datamodenhed: Standardisering af processer og fremme af samarbejde på tværs af afdelinger vil sikre effektiv udnyttelse af data.
Udvidet dataindsamling: VFF bør fokusere på at indsamle mere detaljerede kundedata om VIP-gæster. Dette vil muliggøre en dybere analyse af netværksoplevelsen og dens betydning for fremmødet.

På trods af de nævnte begrænsninger fremhæver projektet vigtigheden af at kombinere organisatoriske forbedringer med tekniske løsninger for at realisere VFF’s mål om effektiv ressourceudnyttelse og optimerede gæsteoplevelser. Når de organisatoriske ændringer er implementeret, vil VFF være bedre rustet til at integrere tekniske løsninger og maksimere værdien af deres data.

# 2. Problemstilling

VFF har samarbejdsaftaler, hvor partnere (VIP-gæster) tildeles guldmenu-billetter til Vesttribunen ved hjemmebanekampe (Interview 1, 2024). VFF oplever i den forbindelse uoverensstemmelse mellem antal bestilte guldmenu-billetter og antal fremmødte VIP-gæster med disse billetter (1. semesterprøven, 2024). 
Dette skaber problemer for flere interessenter (Interview 1, 2024), f.eks. madleverandører, køkkenpersonale og Eventii.
 For disse interessenter medfører de uforudsigelige fremmøde-mønstre madspild, forkert allokering af personale og uudnyttede VIP-faciliteter på Vesttribunen.
Baggrunden for problematikken vedr. data-anvendelse og udnyttelse af tilgængelige data, kan sandsynligvis tilskrives organisationens infrastruktur og datamodenhedsniveau (Respondenter VFF, 2024). Der er på nuværende tidspunkt manglende integration af data på tværs af systemer i de forskellige afdelinger i organisationen samtidig med at parternes billet-brug varierer, hvilket medfører en reduceret stadionoplevelse for fremmødte, hvor den samlede stemning og atmosfære forringes (Respondenter VFF, 2024). Dette er problematisk, da VFF’s mission er at skabe fællesskaber og oplevelser blandt de bedste i Danmark, og visionen er at forene mennesker for at realisere det grønne potentiale (Tea Nørgaard Marketing- og Kommunikationschef, 2024). Derudover medfører det varierende billet-brug, økonomisk spild samt ineffektiv ressourceallokering på kampdage (Interview 1, 2024). 
Organisationen ser ud til at mangle en model eller et system, der kan analysere data og forudsige udnyttelsesgraden på Vesttribunen under VIP-afsnittet. Uden en sådan løsning spildes ressourcer, og det bliver sværere at træffe informerede beslutninger, der kan sikre en sammenhængende og optimeret kampdags-oplevelse.

# 3. Problemformulering

"Hvordan kan VFF anvende eksisterende data om bestilte, benyttede og maksimale guld menu-billetter til at forudsige udnyttelsesgraden blandt VIP-gæster? Og hvordan kan organisationen samtidig fremme sin data-modenhed og infrastruktur, og hvilke konkrete initiativer kan understøtte integrationen af modellen i praksis?""Hvordan kan VFF anvende eksisterende data om bestilte, benyttede og maksimale guld menu-billetter til at forudsige udnyttelsesgraden blandt VIP-gæster? Og hvordan kan organisationen samtidig fremme sin data-modenhed og infrastruktur, og hvilke konkrete initiativer kan understøtte integrationen af modellen i praksis?"

# 4. Afgrænsning

Data om fremmøde på Energi Viborg Arena er afgrænset til VIP-afsnittet på Vesttribunen og gælder kun guldmenu-billetter udleveret gennem samarbejdsaftaler. Datasættet udelukker perioden under corona-krisen og fokuserer på kampe i de sæsoner, hvor VFF har spillet i Superligaen. 
Vi antager desuden, at VFF placerer sig jævnt i Superligaen.

## 4.1. Industri

I dette projekt betragtes VFF som en del af oplevelsesindustrien, hvor organisationen konkurrerer om publikums tid og opmærksomhed med lokale aktiviteter, der finder sted samtidig med hjemmebanekampene. Dette på baggrund af VFF's mission om at skabe fællesskaber og oplevelser, der er blandt de bedste i DK.

## 4.2. ChatGPT

ChatGPT er i denne rapport blevet anvendt som en sparringspartner og inspirationskilde. Værktøjet har bidraget til at forbedre formuleringer og skabe en mere ensartet struktur i teksten. Derudover er det blevet brugt til idéudvikling og til at sikre klarhed i rapportens indhold.

# 5. Definitioner og forkortelser

VIP-gæster = partnere med guldmenuer inkluderet i deres samarbejdsaftale
Viborg Fodsports Forening = VFF
Energi Viborg Arena = Viborg Stadion
Desuden anvendes almindelige sproglige forkortelser, som typisk forekommer i skriftligt dansk, hvor det er relevant.

# 6. Videnskabsteori og metode
## 6.1. Ontologi
### 6.1.1. Problem

Projektet tager udgangspunkt i kritisk realisme, da denne tilgang gør det muligt at analysere sammenhænge mellem observerbare data, som antallet af bestilte og anvendte billetter, samtidig med at undersøge de underliggende mekanismer, som kan påvirke fremmødet, hvilket er relevant for VFF.
Kritisk realisme giver mulighed for at undersøge på Bhaskars tre niveauer (Egholm, 2014):
1.	På det virkelige niveau undersøger vi de strukturer og faktorer, der påvirker udnyttelsesgraden af guld menu-billetter blandt VIP-gæster, samt analyserer VFF’s data-modenhed og infrastruktur.
2.	På det faktiske niveau udvikler vi en model til forudsigelse af udnyttelsesgraden samt analysere VFF’s data modenhedsniveau med fokus på områder til forbedring.
3.	På det empiriske niveau evaluerer vi modellens præcision og kommer med et løsningsforslag til, hvordan organisationen kan styrke sin datamodenhed og infrastruktur. 

### 6.1.2. Paradigmevalg

Vi anvender paradigmet kritisk realisme (Egholm, 2014), da det gør det muligt at analysere både observerbare sociale fænomener (fremmødemønstre) og de underliggende mekanismer, der driver dem (virksomhedskultur og eksterne faktorer som vejr og Superliga-placering). Ved at antage dybdeniveauers eksistens opstilles hypoteser om potentielle sammenhænge, som testes for at validere de bagvedliggende strukturer. Kritisk realisme, der kombinerer natur- og samfundsvidenskabelige metoder, gør det derved muligt at identificere faktorer, der påvirker VIP-gæsters fremmøde, forbedre forudsigelsen af guldmenu-billetudnyttelse og udvikle løsninger, der fremmer organisationens datamodenhed.

### 6.1.3. Retroduktion

Ved at anvende en retroduktiv tilgang (inden for kritisk realisme) (Egholm, 2014) kan vi i undersøgelsen kombinere kvantitative data (guldmenu-billetter og x-variabler) med kvalitative indsigter, der afdækker underliggende mekanismer i organisationen, som indirekte kan påvirke dataudnyttelse og dermed forudsigelsens nøjagtighed i fremmødemønstre. Retroduktionen muliggør en analyse af både det observerede og de dybere strukturer, der påvirker fremmødet, ved at bevæge os mellem induktion (identifikation af datamønstre) og deduktion (hypotesetest). Dette sikrer et solidt grundlag for udviklingen af realistiske og tilpassede løsninger til VFF.

## 6.2. Epistemologi

Kritisk realisme balancerer objektive data og subjektive indsigter, hvilket muliggør en kombination af kvantitative analyser og kvalitative interviews (Egholm, 2014).

### 6.2.1. Kvalitative data oog kvantitative data

Den metodiske pluralisme i kritisk realisme (Egholm, 2014) understøtter brugen af kvantitative data fra guld menu-registreringer til at identificere faktorer, der kan påvirke fremmødet, og kvalitative data fra interviews til at analysere organisationens datamodenhed. 

### 6.2.2. Sekundære og primære data

Vores primære data indsamler vi gennem vores egne metoder, såsom interviews.
Vores sekundære data består af de eksisterende data, vi har fået fra VFF (guld-ark) samt eksterne data fra kilder som Superstats (Superstats, u.d.) og DMI (DMI, u.d.), som understøtter vores undersøgelse.

## 6.3. Metodologi
### 6.3.1. Undersøgelsesdesign

Blandede metoder (Egholm, 2014), fordi de muliggør kombination af kvantitative analyser af fremmødemønstre og kvalitative interviews for at afdække organisatoriske udfordringer.

### 6.3.2. Metoder

Projektet er et casestudie, der analyserer udfordringer med datamodenhed og billetudnyttelse. Gennem semistrukturerede interviews og dataanalyse (som CRISP-DM sætter rammen for) undersøges faktorer, der hhv. påvirker organisationens strategiske brug af data og faktorer der kan have betydning for udnyttelsesgraden, herunder udvælgelse af machine learnings model (Gareth James, 2023) til forudsigelse. 
R-studio anvendes som det primære værktøj til dataanalyse og modellering. Med brug af fleksible pakker som tidyverse, caret og ggplot2 blev datarensning, visualisering og udvikling af prædiktive modeller struktureret i sektioner for dataimport, EDA (Exploratory Data Analysis) og modellering. Dette sikrede gennemsigtighed og reproducerbarhed i analyseprocessen og understøttede en systematisk anvendelse af CRISP-DM-metoden i projektet.
Kotter’s 8-trins model (Bang, 2024) bruges til at koble teori og praksis i udviklingen af løsninger.

#### 6.3.2.1. Datageneereringsprocessen

Processen for indsamling af empirisk data er kort beskrevet nedenfor. For uddybelse af processen se bilag 1.
Empirisk data blev indsamlet via semistrukturerede interviews med fire VFF-medarbejdere og tre praktikanter fra forskellige afdelinger. Fokusområder inkluderede infrastruktur, VIP-fremmøde og netværksoplevelser, hvilket danner grundlag for projektets analyser og løsninger.

#### 6.3.2.2. Præsentationer og præsentationsanalyse

Transskribering af interview 1 vedlagt som:			Bilag 2
Transskribering af interview 2 vedlagt som:			Bilag 3
Interviewanalyse vedlagt som:                   Bilag 4

#### 6.3.2.3.	Præsentationer og præsentationsanalyse

Præsentationsanalysen er baseret på præsentationerne fra Dataafdelingen (Dataafdelingen, 2024) og Marketingsafdelingen (Marketingafdelingen, 2024) og er vedlagt som bilag 5.

# 7. Analyse

CRISP-DM (Bang, 2024) bruges som nævnt til at sætte rammen for projektet, da denne model sikrer en systematisk tilgang og værdi fra data. En kort beskrivelse og modellens relevans for projektet findes i bilag 6.

## 7.1. Forretningsforståelse

VFF udfordres med at forudsige fremmødet af VIP-gæster med guldmenu til hjemmekampe. Projektet sigter mod at udvikle en machine learning-model, der optimerer ressourcer og forbedrer gæsteoplevelsen.
Præsentations- og interviewanalyser afslørede, at VFF’s udfordringer skyldes både forudsigelsesproblemer og silo-tendenser, der hæmmer dataintegration og kommunikation.
VFF har implementeret en ordning, hvor uaktiverede billetter frigives før kampstart, hvilket reducerer fremmødeusikkerhed.

Dette initiativ er et skridt mod at reducere uforudsigeligheden omkring fremmødet. Samtidig fremhæver det behovet for en mere struktureret tilgang til datahåndtering, hvor en forudsigelsesmodel kan anvendes som et redskab til at udnytte eksisterende data mere effektivt og understøtte organisationens overordnede mål om at styrke datamodenheden

### 7.1.1. Organisatinsstruktur og kultur

VFF driver professionel fodbold og arbejder målrettet på at skabe fællesskaber og unikke oplevelser (Bierholm, 2023-2024). Virksomheden har en vision om at være blandt de bedste i Danmark og stræber efter at gøre deres arrangementer så oplevelsesrige, at fodboldkampene bliver en mindre del af en større helhedsoplevelse (Interview 1, 2024).
Virksomheden er opdelt i to hovedafdelinger: en sportsafdeling og en administrativ afdeling. Den administrative afdeling består af cirka 20-25 ansatte og opererer med en flad struktur.
Den administrative afdeling er yderligere opdelt i funktioner med egne specialiseringer. Nogle af funktionerne har egen leder. Den horisontale arbejdsdeling gør det muligt for medarbejderne at dele viden og ekspertise på tværs af organisationen.
Den funktionsopdelte struktur hos VFF har ført til silo-dannelser, hvor afdelingerne arbejder med egne systemer og data. I organisationens decentraliserede tilgang træffes beslutninger tæt på medarbejderne. Dette giver en medarbejder mulighed for at dele en interessant opdagelse i sine egne data med en kollega i en relevant afdeling, som kan anvende den (Interview 1, 2024).
Siloerne har dog haft en negativ indflydelse på den interne kommunikation, idet forskellige afdelinger ofte anvender forskellige definitioner og fortolkninger af centrale områder, f.eks. forklaring af VIP-billetter. Organisationen oplever det som en ressourcekrævende udfordring at integrere data mere effektivt på tværs af afdelingerne (Interview 1, 2024). 
For at forbedre analyserne anbefales det, at VFF indsamler flere kundedata om VIP-gæster med guldmenu-billetter. Dette vil ikke kun understøtte organisationens datamodenhed, men også give mulighed for at analysere, hvordan netværksoplevelsen påvirker fremmødemønstre. En dybere forståelse af denne dimension kan bidrage til mere målrettede tiltag og forbedret gæsteoplevelse.
Udviklingen i sportens verden har ikke kun haft indflydelse på VFF sportsafdelingen, men også i den administrative afdeling. I de seneste år har VFF besluttet at bruge data i deres beslutningstagning, i stedet for at gå med mavefornemmelser og oplevelser (Interview 1, 2024).

### 7.1.2. Business Proces Mapping

![Figur 1, Egen fremstilling udarbejdet vha. Smartdraw.com](Business_Proces_Mapping.png)

VFF har de seneste år arbejdet på at blive en datadrevet organisation, hvor beslutninger i højere grad træffes på baggrund af data. Dette har medført en øget brug af data på tværs af afdelinger, men der er stadig udfordringer med varierende IT-kompetencer blandt medarbejderne. Data indsamles fra forskellige kilder og deles på forskellige måder, især som Excel-filer. Opbevaring og organisering af data sker ofte i et ad hoc-setup, hvor data gemmes på medarbejdernes individuelle computere. VFF’s kommunikation er fleksibel, men denne fleksibilitet fører til ineffektivitet, da den skaber silo-dannelse, manglende overblik og tidsspild. Samlet set har VFF gjort fremskridt mod at blive en mere datadrevet organisation, men der er behov for at standardisere processer for opbevaring, organisering og deling af data for bedre at udnytte data (se bilag 7).

### 7.1.3. Datamodenhed

VFF’s data-modenhedsniveau analyseres i bilag 8 for at identificere, hvor organisationen befinder sig på nuværende tidspunkt. Dette gøres vha. CMMI Institutes Data Management Maturity Model (Datadrevet bog kap. 2, s. 47), da vi med denne model kan identificere de områder, hvor organisationens nuværende praksis understøtter succes samt de områder, hvor de kunne bruge forbedring.  
Modenhedsvurdering af datahåndtering
Analysen viser, at organisationen samlet set befinder sig på niveau 2: Reactive, med variationer på tværs af de seks hovedkategorier. Selvom der er etableret grundlæggende processer, hæmmer manglen på ensartede retningslinjer, kvalitetssikring og systemintegration organisationens effektivitet, hvilket fremhæver behovet for standardisering af processer og et styrket samarbejde på tværs af afdelingerne. 
Denne vurdering danner et solidt grundlag for vores videre udvikling af et realistisk løsningsforslag til VFF.

## 7.2. Dataforståelse

I denne fase af projektet undersøges de tilgængelige data for at opnå en dybere indsigt i deres struktur og relevans. Dette omfatter en analyse af data om guldmenuer, fremmødemønstre og billetbrug for at identificere mønstre og potentielle udfordringer.
I bilag 9 undersøges en mulig sammenhæng mellem VFF’s hjemmekampe og lokale arrangementer. Der blev ikke fundet en betydelig sammenhæng, hvilket tilskrives begrænset dataadgang. Med historiske data fra f.eks. Viborg Kommunes ‘Det sker’ (Kommune, u.d.) kunne analysen have været mere omfattende.

### 7.2.1. Datakilder

De tre primære datakilder for programmeringsanalysen er:
1.	Data fra Excel-filen: Guld.xlsx. Filen inkluderer data trukket internt fra VFF med detaljer om antal bestilte-, anvendte- og et estimeret antal max for VIP-gæster med guldmenu billetter. 
2.	DMI’s API-data: Vejrdata som inkluderer temperatur, vindhastighed og nedbør m.m., blev hentet og koblet på kampdatoer.
3.	Webscrapede kampdata: Kampe, modstandere, tilskuertal og andre relevante oplysninger fra Superstats.

### 7.2.2. Undersøgelse

Udnyttelsesgraden i de interne data i Guld.xlsx, blev fundet ved at dividere guld_menu_stk med antal_bestilte af VIP-gæster.
API-data fra DMI bidrog med vejrforhold, såsom temperatur, vindhastighed og nedbør m.m., som potentielle prædiktorer for fremmødet (x-variabler).
Superstats-data blev udvidet med yderligere information, herunder oplysninger om modstandere og publikum (x-variabler).
Nye funktioner fra den opdaterede kode
1.	Variablen rolling_goals_3 blev lavet for at beregne gennemsnittet af mål scoret over de seneste tre kampe, hvilket bruges som en indikator for holdets præstationshistorik.
2.  Weather_cat blev tilføjet som en kategorisk variabel, der grupperer vejrforhold i tre kategorier (Good, Moderate, Bad) baseret på temperatur og nedbør. Denne laves for at gøre modellen enklere.
3.  Analyse af korrelationer viste stærke forbindelser mellem vejrforhold, modstander og udnyttelsesgrad.
Interaktioner mellem vejr variabler blev også inkluderet, som fx cloud_cover × humidity, for at identificere skjulte mønstre.

### 7.2.3. Visualisering

Data blev visualiseret for at identificere unormale værdier og finde mulige mønstre. For eksempel viste korrelationerne, at der var en stærk sammenhæng mellem temperatur og udnyttelsesgraden.
Residualplots viste, at præcisionen var blevet forbedret i de opdaterede modeller.
Analyser af interaktionerne afslørede, at både vejret og kampens kontekst spiller en vigtig rolle i variationen af udnyttelsesgraden.

## 7.3. Dataforberedelse

Data klargøres til analyse ved at gennemgå processer som rensning af fejlbehæftede værdier, håndtering af manglende data og transformation til et format, der er egnet til modellering.

### 7.3.1. Rensning

Overflødige kolonner såsom ‘Gule_poletter_stk’ blev fjernet for at fokusere på relevante variabler.
NA-værdier i numeriske kolonner blev importeret med medianer for at sikre et mere realistisk billede afi modellerne.
Dato formater blev standardiseret for at sikre konsistens på tværs af alle datasæt. Dette inkluderede konvertering af alle datoer til et ensartet ‘ÅÅÅÅ-MM-DD’ format, hvilket letter sammenkoblingen af data fra forskellige kilder og sikrer præcis datojustering ved sammenfletning af datasæt.
Ikke-numeriske data som ‘goals’ og ‘time’ blev konverteret til numeriske variabler ved hjælp af string parsing, og forskellige dato formater blev tilpasset til et standardformat.
Der blev anvendt strengere korrelationsfiltre for at fjerne unødvendige gentagelser mellem variablerne og dermed gøre modellen stærkere.

### 7.3.2. Integration

Data fra kilder som DMI’s API, Guld.xlsx og webscraping blev sammenkoblet på datoerne for at skabe en integreret dataramme.
Vejrdata og kampdata blev kombineret med udnyttelsesgraden ved at justere de præcise datoer, så eksterne faktorer som temperatur, luftfugtighed og nedbør blev taget med.

### 7.3.3. Feature Engineering

Ny variabel ‘weather_cat’ blev lavet for at gruppere vejret i kategorierne ‘Good’, ‘Moderate’, ‘Bad’, hvilket forenkler modelleringen.
Tidsmæssige variabler som ‘minutes_since_midnight’ og ‘weekday’ blev tilføjet for at fange tidsmæssige mønstre.
Historiske tendenser blev indarbejdet gennem 'rolling_goals_3' og 'rolling_audience_3', samt nye variabler som 'goal_diff'.
Interaktionsvariabler som ‘cloud_cover * humidity’ blev lavet for at undersøge de kombinerede effekter.

### 7.3.4. Normalisreing og kodning

Kategoriske variabler som kampnavne, modstandere og ‘weather_cat’ blev omdannet til dummy-variabler ved hjælp af dummy-encoding for at se forholdene mellem ”good, moderate og bad” i forhold til kampe og modstandere.
Numeriske variabler blev skaleret ved hjælp af centerring og standardisering for at undgå bias i modellerne, og forbedre modellens evne til at arbejde med kategoriske data.

## 7.4. Modellering

Her anvendes data mining-teknikker og algoritmer til at udvikle modeller, der kan forudsige udnyttelsesgraden for VIP-gæster.

### 7.4.1. Valg af modeller og træning

For at udforske og forbedre udnyttelsesgraden, testede vi fire forskellige statistiske modeller:
1.	Lineær regression: Den har vi brugt som en simpel baseline for at skabe et udgangspunkt for vores projekt og for at kunne se tendenserne rimelig hurtigt i forløbet. 
2.	Lasso regression (L1-regularisering): Den er effektiv til at fjerne unødvendige variabler ved kun at vælge de mest relevante, hvilket forbedrede modellens nøjagtighed og reducerede MSE med cirka 15%. Det giver også god indsigt i, hvilke faktorer der virkelig betyder noget, ved at sætte mindre relevante variabler til 0. For eksempel kan vi se, at 'Antal_bestilte', 'weather_cat', 'rolling_audience_3' og 'weekday/time' har en tydelig indvirkning.
3.	Ridge regression (L2-regularisering): Brugt til at håndtere multikollinearitet og overfitting, men viste sig ikke at være mere effektiv end Lasso.
4.	Random Forest: Fokuserede på ikke-lineære sammenhænge og vigtigheden af specifikke variabler. Denne model blev optimeret med justerede hyperparametre for at forbedre dens præstation, hvilket resulterede i en MSE på 140, en forbedring fra tidligere 150, og et R² på 0.92.

### 7.4.2. Træning og test

Vi delte datasættet op, så 80% blev brugt til træning, og de resterende 20% blev brugt til test. For at vurdere modellernes anvendelighed og stabilitet benyttede vi 5-fold cross-validation. Vi brugte også en “CutDown” hvor vi reducerede variablerne til de vigtigste variabler som havde størst indflydelse på vores resultater. På den måde hjalp det os med at mindske risikoen for overfitting og sikre, at modellerne kunne give stabile resultater.

### 7.4.3. Resultater og fortolkning (MSE, RMSE, R²)

Resultaterne af modelleringen viste, at Random Forest og Ridge Regression præsterede bedst med hensyn til MSE og RMSE, mens Ridge Regression også havde den højeste R²-værdi. De detaljerede resultater fremgår af Tabel 1 nedenfor, og en mere udførlig gennemgang findes i Bilag 10.

![Tabel 1: Egen fremstilling til sammenligning af modellernes præstationer](model_mse_rmse_r2.png)

Random Forest viste sig at have den laveste MSE og RMSE, hvilket gør den særligt egnet til forudsigelse af VIP-gæsternes fremmøde. På baggrund af datasættets begrænsede størrelse vurderes dog, at alle modeller vil drage fordel af en større datamængde.
De vigtigste variabler
I bilaget fremgår der en visualisering i form af en graf, som viser betydningen af de forskellige variabler for udnyttelsesgraden. Herunder ses en tabel oversigt, over betydningen for variablerne baseret på analysen i R-studio:

![Tabel 2: Egen fremstilling](betydning_af_variabler.png)

## 7.5. Evaluering

I denne fase vurderes modellernes præstation for at sikre, at de opfylder de forretningsmæssige krav. Det omfatter validering af modellernes nøjagtighed ved hjælp af testdata og vurdering af, om resultaterne er relevante og anvendelige for VFF’s beslutningsprocesser.

### 7.5.1. Præstationsanalyse

Random Forest modellen fortsatte med at levere de bedste resultater i forhold til andre testede modeller, hvilket blev demonstreret ved den laveste mean squared error (MSE) og den højeste R². Denne model blev forbedret yderligere gennem optimering med nye funktioner, som bidrog til en mere ensartet fordeling i residualplots, indikerende mindre bias og en stærkere modelgeneraliserbarhed.

### 7.5.2. Fortolkning

Analyser og fortolkninger af modellen bekræftede, at vejrforhold (kategoriseret som ‘weather_cat’) og kampkontekst (repræsenteret ved ‘rolling_audience_3’) er kritiske prædiktive faktorer. ‘rolling_audience_3’ havde en betydelig indflydelse på modellens præcision, hvilket blev fremhævet gennem både Lasso og Random Forest modeller. Desuden viste temperatur og modstanderes popularitet sig at have en betydelig indflydelse på fremmødet, hvor en højere temperatur og populære modstandere korrelerede med større fremmøde.

### 7.5.3. Visualisering

Visualiseringerne understøttede disse fund med præcise plots af observeret versus forudsagt fremmøde, som illustrerede Random Forest modellens overlegenhed i præcision. Variable importance-plots afslørede desuden ‘Antal_bestilte’, ‘rolling_audience_3’, og ‘weekday’ som nøglevariable. Disse plots var afgørende for at validere modelpræcisionen og for at vise, hvordan forskellige prædiktorer bidrog til modellens præstationer. Residualplots fra de opdaterede modeller afslørede en reduceret bias og en mere ensartet fejlfordeling sammenlignet med tidligere modeller.

## 7.6. Implementering
### 7.6.1. Anvendelse af machine learnings resultater og anbefalinger

De udviklede prædiktive modeller og deres resultater kan bruges i VFF’s strategiske beslutningsprocesser for at optimere, hvordan ressourcerne fordeles, og forbedre forberedelserne til hjemmekampe. For at gøre vores machine learnings produkt praktisk anvendeligt, vil vi anbefale at etablere dataarkitektur i organisationen. 
Når det overordnede er på plads, kan VFF starte med at anvende vores analyser og modeller til at bygge deres egne modeller eller videreudvikle på dem. Det kræver en grundig indsigt i de data og faktorer, der spiller en rolle for guldmenuerne, så modellerne kan designes og optimeres på bedst mulige måde. 

### 7.6.2. Anbefalinger

På baggrund af de foretaget analyser anbefales det at VFF:
1. Fortsætter den allerede påbegyndte proces med at oprette et Datawarehouse.
2. Anvender Kotter’s 8-trins model som en strategisk ramme for at implementere de organisatoriske ændringer, der er nødvendige for at opnå dataintegration og ejerskab.
I bilag 11 har vi udarbejdet Kotter’s 8-trins model for forandring tilpasset VFF, baseret på vores begrænsede kendskab til organisationen infrastruktur og virksomhedskultur. 

### 7.6.3. Implementeringsforslag

Kotter’s 8-trins model kan hjælpe VFF med at oprette et Datawarehouse og forbedre datamodenhed gennem standardisering, samarbejde og klare retningslinjer og derved sikre en struktureret og effektiv implementering af nye datainitiativer.

# 8. Konklusion

VFF er i vækst og bevæger sig mod at blive en datadrevet organisation, men silo-dannelser og uensartet datahåndtering begrænser effektiviteten. Organisationen er på niveau 2 (Reactive) i datamodenhed, hvilket forhindrer optimal udnyttelse af data og hæmmer strategiske beslutninger.
Projektet viser potentialet i prædiktionsmodeller til at forudsige udnyttelsesgraden af guldmenu-billetter, men begrænsede datamængder og manglende standardisering reducerer modellernes anvendelighed. Dette understreger, at organisatoriske forbedringer, som centralisering af data og etablering af en datadrevet kultur, skal prioriteres før tekniske løsninger som et Datawarehouse.
Implementeringen af Kotter’s 8-trins model anbefales som et strategisk værktøj til at opbygge samarbejde, skabe fælles forståelse og sikre en stærk organisatorisk base. Når disse forandringer er på plads, vil VFF være bedre rustet til at integrere tekniske løsninger og udnytte data mere effektivt.

# 9. Metodekritik oog reflektion

Den største udfordring i projektet var den begrænsede adgang til data, som kun omfattede bestilte og anvendte guldmenu-billetter samt et estimeret antal max. Mere detaljerede data om samarbejdspartnerne kunne have forbedret modellernes præcision og givet indsigt i, hvordan netværksoplevelsen påvirker fremmødet.
Modellen identificerede vejrforhold og kampkontekster som afgørende faktorer for fremmøde, men en kombination af kvantitative og kvalitative data ville kunne give et mere nuanceret billede.
Det er dog bemærkelsesværdigt, at hvis der havde været flere kundedata til rådighed (som antages ville have givet bedre indsigt i faktorer der påvirker fremmødet), havde det stillet yderligere krav om etiske overvejelser og overholdelse af databeskyttelseslovgivning.
De semistrukturerede interviews gav relevante indsigter, men det begrænsede kendskab til enkelte afdelinger kan påvirke resultaternes repræsentativitet, eftersom alle afdelinger i organisationen ikke blev repræsenteret og dette kan have haft betydning for validiteten i projektet.
Samtidig fremgik det under de semistrukturerede interviews, at organisationen er tilfreds med en nuværende udnyttelsesgrad på 81% (Palle, 2024), hvilket skaber en vis afstand mellem projektets mål og VFF’s behov.
På trods af begrænsningerne ift. tilgængelige data viser projektet, at der er potentiale i at anvende teknologiske løsninger og styrke de organisatoriske rammer for at opnå en mere systematisk håndtering af fremmødemønstre og ressourceallokering. 
Implementeringen af løsninger som et datawarehouse og en øget datamodenhed kræver dog langsigtet planlægning og ledelsesopbakning for at sikre succes, hvilket kan understøttes ved brug af Kotter’s 8-trins model. 
Selvom VFF i øjeblikket ikke ser et presserende behov for modellen, kan en styrket dataindsamling og integration bidrage til mere præcise analyser og beslutningsstøtte, som på sigt kan understøtte organisationens strategiske målsætninger om at blive mere datadrevet.

# 10. Litteraturliste

1. semesterprøven, b. (2024). Dataanalyse, Viborg.
Bang, C. G. (2024). Data-Driven Decision-Making for Business. 
Bierholm. (2023-2024). Årsrapport for regnskabsåret , s. 15. 
Dataafdelingen. (2024). Præsentation fra dataafdelingen. Datachef i VFF: Daniel og praktikanter: Frederiks, Olga og Mohammed.
DMI. (u.d.). Hentet fra https://www.dmi.dk
Egholm, L. (2014). Videnskabsteori, perspektiver på organisationer og samfund. Hans Reitzels Forlag.
Gareth James, D. W. (2023). An Introduction to Statistical Learning, with Applications in R. 
Interview 1, T. N.-o. (2024). (D. o. undervisere, Interviewer)
Kommune, V. (u.d.). Det sker i Viborg. Hentet fra https://viborg.dk/oplevelser-og-fritid/det-sker/?ArrKunstner=&Genre=&ArrStartdato=15%2F12%202024&Area=Viborg-postby
Marketingafdelingen. (2024). Præsentation fra Marketing. Marketing- og Kommunikationschef: Tea Nørgaard og Marketingansvarlig: Daniel Lindemann Jakobsen.
Palle. (2024). Præsentation Billetsalg.
Respondenter VFF, p. (2024). Samlet indblik i organisationen fra præsentationer.
Superstats. (u.d.). Hentet fra https://superstats.dk
Tea Nørgaard Marketing- og Kommunikationschef, P. (2024).

# 11. Tabel over figurer

Figur 1, Egen fremstilling udarbejdet vha. Smartdraw.com	s12

Tabel 1: Egen fremstilling til sammenligning af modellernes præstationer s17

Tabel 2: Egen fremstilling s18

# 12. Bilag

Bilag er vedlagt i et separat dokument (med sidetal på)

Bilag 1: Indsamling af empirisk data

Bilag 2: Interview 1 Transskribering

Bilag 3: Interview efter transskribering med descript-webværktøj

Bilag 4: Interviewanalyse

Bilag 5: Analyse af præstationer

Bilag 6: CRISP-DM

Bilag 7: Business Proces Mapping

Bilag 8: Datamodenhedsniveau

Bilag 9: Hjemmekamp og lokalarrangementer

Bilag 10: Resultater og fortolkning (MSE, RMSE, R²)

Bilag 11: Løsningsforslag Kotter’s 8-trins model

# 13. Redegørelse af ændringer i forhold til det oprindelige projekt

De eneste ændringer, der er foretaget, omfatter en revision af nogle få steder for at forklare, hvad der sker i koden og rettelser af stavefejl.








































































